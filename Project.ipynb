{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniproject Joshua Kutschera (heart attack dataset)\n",
    "This project is based on the [Heart Attack Analysis & Prediction Dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/data) from Kaggle.com.\n",
    "\n",
    "[Idea for chart](https://github.com/holoviz/holoviews/issues/3821)\n",
    "\n",
    "## About this dataset:\n",
    "\n",
    "    Age : Age of the patient, \n",
    "\n",
    "    Sex : Sex of the patient, 1=male, 0=female\n",
    "    \n",
    "    cp : Chest Pain type chest pain type\n",
    "            Value 1: typical angina\n",
    "            Value 2: atypical angina\n",
    "            Value 3: non-anginal pain\n",
    "            Value 4: asymptomatic\n",
    "            \n",
    "    trtbps : resting blood pressure (in mm Hg)\n",
    "\n",
    "    chol : cholestoral in mg/dl fetched via BMI sensor\n",
    "\n",
    "    fbs : (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "    \n",
    "    rest_ecg : resting electrocardiographic results\n",
    "            Value 0: normal\n",
    "            Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "            Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "            \n",
    "    thalach : maximum heart rate achieved\n",
    "\n",
    "    exng: exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "    oldpeak: ST depression induced by exercise relative to rest (float)\n",
    "\n",
    "    slp: Slope of the peak exercise ST segment \n",
    "        1= upsloping\n",
    "        2= flat\n",
    "        3= downsloping\n",
    "        \n",
    "    caa: number of major vessels (0-3)\n",
    "\n",
    "    thall: thal: A blood disorder called thalassemia\n",
    "        Value 0: NULL (dropped from the dataset previously\n",
    "\n",
    "        Value 1: fixed defect (no blood flow in some part of the heart)\n",
    "        \n",
    "        Value 2: normal blood flow\n",
    "        \n",
    "        Value 3: reversible defect (a blood flow is observed but it is not normal)\n",
    "    \n",
    "    output (target): 0= less chance of heart attack 1= more chance of heart attack\n",
    "    \n",
    "## Dataset Overview\n",
    "- `age`, `sex`, `cp`, `trtbps`, `chol`, etc., are the features.\n",
    "- `output` (1 or 0) is the target variable (1 = risk of heart attack)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Questions\n",
    "Who is at risk of having a heart attack?\n",
    "What is the biggest factor playing into being at risk?\n",
    "\n",
    "\n",
    " -   Find your favourite dataset\n",
    " -   Describe origin and specification of these data\n",
    " -   Find 2 research questions (prediction context)\n",
    " -   Plot variables of interest (both 1- and 2-variable plots)\n",
    " -   Interpret plots\n",
    " -   Fit tree, random forest to answer questions\n",
    " -   Describe performance (validation, train/test, cross validation)\n",
    " -   Compare with linear model (or logistic linear model)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:54:47.973010Z",
     "start_time": "2024-12-17T17:54:47.721289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from math import sqrt\n",
    "from scipy.stats import entropy"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:56:59.380863Z",
     "start_time": "2024-12-17T17:56:59.298113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: Load and Describe Dataset\n",
    "heart_data = pd.read_csv(\"Data/heart.csv\")\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(heart_data.head())\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "print(heart_data.info())\n",
    "\n",
    "# Describe the dataset statistics\n",
    "print(\"\\nDataset Description:\")\n",
    "print(heart_data.describe())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
      "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
      "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
      "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
      "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
      "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
      "\n",
      "   caa  thall  output  \n",
      "0    0      1       1  \n",
      "1    0      2       1  \n",
      "2    0      2       1  \n",
      "3    0      2       1  \n",
      "4    0      2       1  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trtbps    303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalachh  303 non-null    int64  \n",
      " 8   exng      303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slp       303 non-null    int64  \n",
      " 11  caa       303 non-null    int64  \n",
      " 12  thall     303 non-null    int64  \n",
      " 13  output    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n",
      "None\n",
      "\n",
      "Dataset Description:\n",
      "              age         sex          cp      trtbps        chol         fbs  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
      "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
      "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
      "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
      "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
      "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
      "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
      "\n",
      "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
      "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
      "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
      "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
      "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
      "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
      "\n",
      "            thall      output  \n",
      "count  303.000000  303.000000  \n",
      "mean     2.313531    0.544554  \n",
      "std      0.612277    0.498835  \n",
      "min      0.000000    0.000000  \n",
      "25%      2.000000    0.000000  \n",
      "50%      2.000000    1.000000  \n",
      "75%      3.000000    1.000000  \n",
      "max      3.000000    1.000000  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# data = np.loadtxt(\"./Data/heart.csv\", delimiter=\",\", skiprows=1)\n",
    "# X = data[:, :-1]\n",
    "# Y = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8524590163934426\n",
      "Feature Importances:\n",
      "Feature 0: 0.07656258321357846\n",
      "Feature 1: 0.037190916301048496\n",
      "Feature 2: 0.08372473207079724\n",
      "Feature 3: 0.073102984540921\n",
      "Feature 4: 0.08830322771673946\n",
      "Feature 5: 0.017574305947343678\n",
      "Feature 6: 0.02388805612055446\n",
      "Feature 7: 0.1288887993723594\n",
      "Feature 8: 0.09452967791135913\n",
      "Feature 9: 0.09609913623121151\n",
      "Feature 10: 0.06726894376432285\n",
      "Feature 11: 0.1263750158499526\n",
      "Feature 12: 0.08649162095981171\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# \n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "# \n",
    "# clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "# \n",
    "# clf.fit(X_train, Y_train)\n",
    "# \n",
    "# \n",
    "# predictions = clf.predict(X_test)\n",
    "# accuracy = accuracy_score(Y_test, predictions)\n",
    "# print(\"Test Accuracy:\", accuracy)\n",
    "# feature_importances = clf.feature_importances_\n",
    "# \n",
    "# print(\"Feature Importances:\")\n",
    "# for i, importance in enumerate(feature_importances):\n",
    "#     print(f\"Feature {i}: {importance}\")\n",
    "# \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
